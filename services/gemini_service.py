
from google import genai

import httpx
from services.db_service import upsert_course_vector
from utils.config import GEMINI_API_KEY, MAIN_SERVICE_URL
import json
import math

client = genai.Client(api_key=GEMINI_API_KEY)

BATCH_SIZE = 50

def get_feedback(
    source_code: str, problem_description: str, expected_output: str, judge_output: str
):
    prompt = f"""
    Báº¡n lÃ  má»™t giÃ¡o viÃªn láº­p trÃ¬nh chuyÃªn nghiá»‡p. HÃ£y Ä‘Ã¡nh giÃ¡ code cá»§a há»c sinh.

    ğŸ“ **Äá» bÃ i:**
    {problem_description}

    ğŸ’» **Code cá»§a há»c sinh:**
    ```
    {source_code}
    ```

    âœ… **Káº¿t quáº£ mong Ä‘á»£i:**
    {expected_output}

    ğŸ“Š **Káº¿t quáº£ thá»±c táº¿ tá»« Judge0:**
    {judge_output}

    HÃ£y tráº£ vá» feedback dÆ°á»›i dáº¡ng JSON vá»›i cáº¥u trÃºc sau (chá»‰ tráº£ JSON, khÃ´ng thÃªm text khÃ¡c):
    {{
        "score": 0-100,
        "summary": "TÃ³m táº¯t ngáº¯n gá»n vá» bÃ i lÃ m",
        "strengths": ["Äiá»ƒm máº¡nh 1", "Äiá»ƒm máº¡nh 2"],
        "weaknesses": ["Äiá»ƒm yáº¿u 1", "Äiá»ƒm yáº¿u 2"],
        "suggestions": ["Gá»£i Ã½ cáº£i thiá»‡n 1", "Gá»£i Ã½ cáº£i thiá»‡n 2"],
        "code_quality": {{
            "readability": 0-100 %,
            "efficiency": 0-100 %,
            "best_practices": 0-100 %
        }}
    }}

    **YÃªu cáº§u:**
    - is_correct: true náº¿u output khá»›p hoÃ n toÃ n vá»›i expected_output
    - score: Ä‘iá»ƒm tá»•ng thá»ƒ tá»« 0-100
    - summary: 1-2 cÃ¢u tÃ³m táº¯t
    - strengths: liá»‡t kÃª cÃ¡c Ä‘iá»ƒm tá»‘t (tá»‘i thiá»ƒu 1-2 Ä‘iá»ƒm)
    - weaknesses: liá»‡t kÃª cÃ¡c váº¥n Ä‘á» (náº¿u cÃ³, cÃ³ thá»ƒ Ä‘á»ƒ máº£ng rá»—ng náº¿u code hoÃ n háº£o)
    - suggestions: Ä‘á» xuáº¥t cáº£i thiá»‡n (náº¿u cÃ³)
    - code_quality: Ä‘Ã¡nh giÃ¡ 3 tiÃªu chÃ­ tá»« 0-10

    Chá»‰ tráº£ vá» JSON thuáº§n, khÃ´ng thÃªm markdown hay text khÃ¡c.
    """

    # ğŸ“Œ Gá»i Gemini theo SDK má»›i
    response = client.models.generate_content(
        model="gemini-2.5-flash",
        contents=prompt
    )

    text = response.text.strip()

    # ğŸ§¹ LÃ m sáº¡ch JSON náº¿u LLM tá»± bao block markdown
    if text.startswith("```json"):
        text = text[7:]
    if text.startswith("```"):
        text = text[3:]
    if text.endswith("```"):
        text = text[:-3]
    text = text.strip()

    # ğŸ§¾ Parse JSON
    try:
        return json.loads(text)
    except Exception:
        # Náº¿u JSON khÃ´ng Ä‘Ãºng format, váº«n tráº£ feedback dáº¡ng fallback
        return {
            "is_correct": None,
            "score": 0,
            "summary": text,
            "strengths": [],
            "weaknesses": ["KhÃ´ng phÃ¢n tÃ­ch Ä‘Æ°á»£c feedback"],
            "suggestions": [],
            "code_quality": {"readability": 0, "efficiency": 0, "best_practices": 0},
        }

async def process_courses():
    async with httpx.AsyncClient() as http:
        body = (await http.get(f"{MAIN_SERVICE_URL}/v1/courses")).json()
        courses = body.get("data", [])

    if not courses:
        print("âš  KhÃ´ng cÃ³ khÃ³a há»c nÃ o.")
        return

    total = len(courses)
    batches = math.ceil(total / BATCH_SIZE)
    success = 0

    for b in range(batches):
        chunk = courses[b * BATCH_SIZE : (b + 1) * BATCH_SIZE]

        contents = [
            f"{c['title']}\n{c['description']}\n{c.get('learningObjectives', '')}"
            for c in chunk
        ]

        try:
            result = client.models.embed_content(
                model="gemini-embedding-001",
                contents=contents  # âœ” API chuáº©n SDK má»›i
            )

            vectors = [emb.values for emb in result.embeddings]  # list[list[float]]

            for idx, c in enumerate(chunk):
                upsert_course_vector(c["courseId"], vectors[idx])
                success += 1

            print(f"ğŸ”¹ Batch {b+1}/{batches} completed ({len(chunk)} courses)")

        except Exception as e:
            print(f"âŒ Lá»—i batch {b+1}/{batches}: {e}")

    print(f"âœ¨ Done â€” Embedded {success}/{total} courses báº±ng batch")
